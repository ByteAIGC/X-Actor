<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="theme-color" content="#000000" />
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="Open-Sans.css">
  <link rel="stylesheet" href="index.css">
  <title></title>
  <script defer="defer" src="./static/js/main.cb41f6a5.js"></script>
  <link href="./static/css/main.4017e162.css" rel="stylesheet">
  <meta name="description"
        content="X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio">
  <title>X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio</title>
</head>

<body>
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>
  </nav>

  <div id="root" class="column-flex">
    <div id="title-flex" class="column-flex">
      <h1> X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio </h1>
      <span>
        <a href="https://zhangchenxu528.github.io/">Chenxu&nbsp;Zhang</a><sup></sup>,
        <a href="https://lizenan.github.io/">Zenan&nbsp;Li</a>,
        <a href="https://hongyixu37.github.io/homepage/">Hongyi&nbsp;Xu</a>,
        <a href="https://ge.in.tum.de/about/you-xie/">You&nbsp;Xie</a>,
        <a href="https://xiaochen-zhao.netlify.app/">Xiaochen&nbsp;Zhao</a>,
        <a href="https://gutianpei.github.io/">Tianpei&nbsp;Gu</a>,
        <a href="https://guoxiansong.github.io/homepage/">Guoxian&nbsp;Song</a>,
        <a href="https://chenxin.tech/">Xin&nbsp;Chen</a>,
        <a target="_blank" href="" onclick="return false;">Chao&nbsp;Liang</a>,
        <a href="https://jianwenjiang.github.io">Jianwen&nbsp;Jiang</a>,
        <a href="https://linjieluo.github.io/">Linjie&nbsp;Luo</a>
        <br />
      </span>
      <span>ByteDance Inc.</span>
      <div class="flex flex-gap" style="margin-bottom:0.5em;">
        <a target="_blank" href="" onclick="return false;"><button>Paper</button></a>
        <a target="_blank" href="" onclick="return false;"><button>Page</button></a>
      </div>
    </div>

    
    <div id="sections" class="column-flex">
      <h3></h3>
      <div class="video-slider">
        <video src="all_teaser/teaser2.mp4"></video>
        <video src="all_teaser/teaser16.mp4"></video>
        <video src="all_teaser/teaser7.mp4"></video>
        <video src="all_teaser/teaser11.mp4"></video>
      </div>
      <div class="video-slider">
        <video src="all_teaser/teaser1.mp4"></video>
        <video src="all_teaser/teaser10.mp4"></video>
        <video src="all_teaser/teaser14.mp4"></video>
        <video src="all_teaser/teaser13.mp4"></video>
      </div>
      
      <br>
      <h3>Pipeline</h3>
      <div class='responsive-image-container'>
        <img src='image/x_actor_overview.png' alt='' style="margin: 0 auto; width: 90%; height: auto;"/>
      </div>
      <small><span>X-Actor decouples video synthesis from audio-conditioned motion generation, operating in a compact, expressive, and identity-agnostic facial motion latent space. Specifically, we encode talking video frames into sequences of motion latents using a pretrained motion encoder. These latents are corrupted with asynchronously sampled noise levels and denoised using an autoregressive diffusion model trained with a diffusion-forcing scheme. Within each motion chunk, we apply full self-attention to preserve fine-grained expressiveness, while causal cross-chunk attention ensures long-range temporal coherence and context awareness. Each motion token attends to frame-aligned audio features via windowed cross-attention, enabling accurate lip synchronization and capturing transient emotional shifts. At inference time, we autoregressively and iteratively predict future motion tokens with a monotonically decreasing noise schedule over the historical motion context. Finally, alongside a single reference image, we render the predicted motion sequence into high-fidelity, emotionally rich video frames using a pretrained diffusion-based video generator.</span></small>
        

      <h3>Motion Diversity</h3>
      
        <div class="video-slider">
          <video src="motion_diversity_videos/result3.mp4"></video>
          <video src="motion_diversity_videos/result7.mp4"></video>
          <video src="motion_diversity_videos/result8.mp4"></video>
          <video src="motion_diversity_videos/result9.mp4"></video>
          <video src="motion_diversity_videos/result10.mp4"></video>
          <video src="motion_diversity_videos/result11.mp4"></video>
        </div>
      

        <div class="video-slider">
          <video src="motion_diversity_videos/result1.mp4"></video>
          <video src="motion_diversity_videos/result2.mp4"></video>
          <video src="motion_diversity_videos/result12.mp4"></video>
          <video src="motion_diversity_videos/result13.mp4"></video>
          <video src="motion_diversity_videos/result15.mp4"></video>
        </div>


        <div class="video-slider">
          <video src="motion_diversity_videos/result4.mp4"></video>
          <video src="motion_diversity_videos/result5.mp4"></video>
          <video src="motion_diversity_videos/result6.mp4"></video>
          <video src="motion_diversity_videos/result14.mp4"></video>
          <video src="motion_diversity_videos/result16.mp4"></video>
          <video src="motion_diversity_videos/result17.mp4"></video>
        </div>
        

      <h3>More Video Results</h3>
        <div class="video-slider">
          <video src="all_teaser/teaser9.mp4"></video>
          <video src="all_teaser/teaser4.mp4"></video>
          <video src="all_teaser/teaser5.mp4"></video>
        </div>
        <div class="video-slider">
          <video src="all_teaser/teaser6.mp4"></video>
          <video src="all_teaser/teaser8.mp4"></video>
          <video src="all_teaser/teaser15.mp4"></video>
         
        </div>
        <div class="video-slider">
          <video src="all_teaser/teaser12.mp4"></video>
          <video src="all_teaser/teaser3.mp4"></video>
        </div>


      <h3>Compare with Recent Methods</h3>
        <div class="video-container">
          <video controls playsInline src="baselines/baseline1_new.mp4"></video>
        </div>
        <div class="video-container">
          <video controls playsInline src="baselines/baseline2_new.mp4"></video>
        </div>
        <div class="video-container">
          <video controls playsInline src="baselines/baseline3_new.mp4"></video>
        </div>
      
        <h3>Ablation Study</h3>
        <div class="video-container">
          <video controls playsInline src="ablation/ablation1.mp4"></video>
        </div>
        <div class="video-container">
          <video controls playsInline src="ablation/ablation2.mp4"></video>
        </div>

        <h3>Ethics Concerns</h3>
        <p>
          The images and music used in demos are from public sources or generated by models, and are solely used to demonstrate the capabilities of this research work. If there are any concerns, please contact us (chenxuzhang@bytedance.com) and we will delete it in time. 
        </p>


      <br/>
      <br/>
      <br/>
    </div>
  </div>
  <script src="index.js"></script>
  <script>
    function comming_soon_click() {
      alert('Comming soon!');
    }
    function TBD_click() {
      alert('TBD');
    }
  </script>
</body>



</html>
